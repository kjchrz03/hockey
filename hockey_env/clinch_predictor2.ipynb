{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from pprint import pprint\n",
    "import pytz\n",
    "import seaborn as sb\n",
    "import schedule\n",
    "from hockey_rink import NHLRink\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from datetime import date\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import time\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "import re\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, RFE, mutual_info_classif\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import asyncio\n",
    "import aiohttp\n",
    "import nest_asyncio\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daily Games since 12/26/24 - 1/18/25\n",
    "\n",
    "\n",
    "# Initialize the DataFrame\n",
    "daily_games = pd.DataFrame()\n",
    "\n",
    "base_url = \"https://api-web.nhle.com/v1/schedule/\"\n",
    "start_date = datetime.strptime(\"2024-10-04\", \"%Y-%m-%d\")\n",
    "end_date = datetime.strptime(\"2025-04-17\", \"%Y-%m-%d\")\n",
    "\n",
    "\n",
    "current_date = start_date\n",
    "\n",
    "# Set to keep track of unique dates\n",
    "seen_dates = set()\n",
    "\n",
    "while current_date <= end_date:\n",
    "    # Format the date as 'YYYY-MM-DD'\n",
    "    formatted_date = current_date.strftime(\"%Y-%m-%d\")\n",
    "    api_url = f\"{base_url}{formatted_date}\"\n",
    "\n",
    "    # Make the API request\n",
    "    response = requests.get(api_url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        # The response content can be accessed using response.text\n",
    "        response_text = response.text\n",
    "    # pprint(response_text)\n",
    "    else:\n",
    "        print(f\"Request failed with status code {response.status_code}\")\n",
    "\n",
    "    json_data = json.loads(response_text)\n",
    "\n",
    "    game_week = json_data[\"gameWeek\"]\n",
    "    game_week_df = pd.DataFrame(game_week)\n",
    "\n",
    "    game_week_df = game_week_df[game_week_df[\"numberOfGames\"] != 0]\n",
    "\n",
    "    # Filter out rows with duplicate dates\n",
    "    if formatted_date not in seen_dates:\n",
    "        seen_dates.add(formatted_date)\n",
    "        daily_games = pd.concat([daily_games, game_week_df], ignore_index=True)\n",
    "    else:\n",
    "        print(f\"Failed to retrieve data for {formatted_date}\")\n",
    "\n",
    "    # Move to the next week\n",
    "    current_date += timedelta(weeks=1)\n",
    "    # Filter out rows where 'date' is after the end date\n",
    "    daily_games[\"date\"] = pd.to_datetime(daily_games[\"date\"])\n",
    "    daily_games = daily_games[daily_games[\"date\"] <= end_date]\n",
    "\n",
    "    # Reset index after filtering\n",
    "    daily_games.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    game_week_details = pd.json_normalize(daily_games[\"games\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in order to extract the data properly, it needs to be stored in a dictionary. This extracts each of the games from the cells\n",
    "\n",
    "dfs = {}\n",
    "\n",
    "# Loop through the iterations (30 times)\n",
    "for i in range(0, len(game_week_details.columns)):\n",
    "    api_response = game_week\n",
    "\n",
    "    if api_response is not None:\n",
    "        # Extract relevant data from the API response and normalize it\n",
    "        game_info = pd.json_normalize(game_week_details[i])\n",
    "\n",
    "        # Create a DataFrame for this iteration\n",
    "        df_name = f\"game_test{i}\"  # Generate a unique variable name\n",
    "        dfs[df_name] = pd.DataFrame(game_info)\n",
    "    else:\n",
    "        # Handle the case where the API request failed\n",
    "        print(f\"API request failed for index {i}\")\n",
    "\n",
    "# Then I combine all of the dfs in the list by concatenation to create a single df. now all of the game data is spread out across each row.\n",
    "combined_df = pd.concat(dfs.values(), ignore_index=True)\n",
    "combined_df.dropna(how=\"all\", inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = combined_df[\n",
    "    [\n",
    "        \"id\",\n",
    "        \"season\",\n",
    "        \"startTimeUTC\",\n",
    "        \"gameType\",\n",
    "        \"awayTeam.id\",\n",
    "        \"awayTeam.abbrev\",\n",
    "        \"awayTeam.logo\",\n",
    "        \"homeTeam.id\",\n",
    "        \"homeTeam.abbrev\",\n",
    "        \"homeTeam.logo\",\n",
    "        \"homeTeam.placeName.default\",\n",
    "        \"awayTeam.placeName.default\",\n",
    "        \"awayTeam.score\",\n",
    "        \"homeTeam.score\",\n",
    "        \"winningGoalScorer.playerId\",\n",
    "        \"winningGoalie.playerId\",\n",
    "        \"gameState\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "\n",
    "combined_df = combined_df.convert_dtypes()\n",
    "combined_df[\"id\"] = combined_df[\"id\"].astype(str)\n",
    "combined_df[combined_df[\"gameType\"] == 2]\n",
    "combined_df[\"link\"] = (\n",
    "    \"https://api-web.nhle.com/v1/gamecenter/\" + combined_df[\"id\"] + \"/play-by-play\"\n",
    ")\n",
    "\n",
    "# Assuming '<NA>' is a string, replace it with np.nan\n",
    "combined_df[\"id\"] = combined_df[\"id\"].replace(\"<NA>\", np.nan)\n",
    "\n",
    "# Drop rows with NaN values in the 'link' column\n",
    "combined_df = combined_df.dropna(subset=[\"id\"])\n",
    "combined_df = combined_df.query('gameState == \"OFF\"')\n",
    "combined_df[\"startTimeUTC\"] = pd.to_datetime(combined_df[\"startTimeUTC\"])\n",
    "combined_df = combined_df.rename(columns={\"id\": \"game_id\"})\n",
    "combined_df = combined_df.sort_values(\"game_id\").reset_index()\n",
    "\n",
    "\n",
    "# Specify the UTC time zone\n",
    "utc_timezone = pytz.utc\n",
    "\n",
    "# Specify the target time zone (Eastern Time)\n",
    "eastern_timezone = pytz.timezone(\"America/New_York\")\n",
    "\n",
    "# Convert 'startTimeUTC' to Eastern Time\n",
    "combined_df[\"game_date_time\"] = combined_df[\"startTimeUTC\"].dt.tz_convert(\n",
    "    eastern_timezone\n",
    ")\n",
    "combined_df[\"game_date_time\"] = pd.to_datetime(combined_df[\"game_date_time\"])\n",
    "combined_df[\"start_time\"] = (\n",
    "    combined_df[\"game_date_time\"].dt.strftime(\"%I:%M %p\").str.lstrip(\"0\").str.lower()\n",
    ")\n",
    "combined_df[\"game_date\"] = combined_df[\"game_date_time\"].dt.strftime(\"%Y-%m-%d\")\n",
    "combined_df.drop(\"startTimeUTC\", axis=1, inplace=True)\n",
    "# combined_df = combined_df[combined_df['game_date'] == formatted_date]\n",
    "combined_df.sort_values(by=\"game_id\")\n",
    "# print(\"combined_df done\")\n",
    "combined_df.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = combined_df[\n",
    "    [\n",
    "        \"id\",\n",
    "        \"season\",\n",
    "        \"startTimeUTC\",\n",
    "        \"gameType\",\n",
    "        \"awayTeam.id\",\n",
    "        \"awayTeam.abbrev\",\n",
    "        \"awayTeam.logo\",\n",
    "        \"homeTeam.id\",\n",
    "        \"homeTeam.abbrev\",\n",
    "        \"homeTeam.logo\",\n",
    "        \"homeTeam.placeName.default\",\n",
    "        \"awayTeam.placeName.default\",\n",
    "        \"awayTeam.score\",\n",
    "        \"homeTeam.score\",\n",
    "        \"winningGoalScorer.playerId\",\n",
    "        \"winningGoalie.playerId\",\n",
    "        \"gameState\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "\n",
    "combined_df = combined_df.convert_dtypes()\n",
    "combined_df[\"id\"] = combined_df[\"id\"].astype(str)\n",
    "combined_df[combined_df[\"gameType\"] == 2]\n",
    "combined_df[\"link\"] = (\n",
    "    \"https://api-web.nhle.com/v1/gamecenter/\" + combined_df[\"id\"] + \"/play-by-play\"\n",
    ")\n",
    "\n",
    "# Assuming '<NA>' is a string, replace it with np.nan\n",
    "combined_df[\"id\"] = combined_df[\"id\"].replace(\"<NA>\", np.nan)\n",
    "\n",
    "# Drop rows with NaN values in the 'link' column\n",
    "combined_df = combined_df.dropna(subset=[\"id\"])\n",
    "combined_df = combined_df.query('gameState == \"OFF\"')\n",
    "combined_df[\"startTimeUTC\"] = pd.to_datetime(combined_df[\"startTimeUTC\"])\n",
    "combined_df = combined_df.rename(columns={\"id\": \"game_id\"})\n",
    "combined_df = combined_df.sort_values(\"game_id\").reset_index()\n",
    "\n",
    "\n",
    "# Specify the UTC time zone\n",
    "utc_timezone = pytz.utc\n",
    "\n",
    "# Specify the target time zone (Eastern Time)\n",
    "eastern_timezone = pytz.timezone(\"America/New_York\")\n",
    "\n",
    "# Convert 'startTimeUTC' to Eastern Time\n",
    "combined_df[\"game_date_time\"] = combined_df[\"startTimeUTC\"].dt.tz_convert(\n",
    "    eastern_timezone\n",
    ")\n",
    "combined_df[\"game_date_time\"] = pd.to_datetime(combined_df[\"game_date_time\"])\n",
    "combined_df[\"start_time\"] = (\n",
    "    combined_df[\"game_date_time\"].dt.strftime(\"%I:%M %p\").str.lstrip(\"0\").str.lower()\n",
    ")\n",
    "combined_df[\"game_date\"] = combined_df[\"game_date_time\"].dt.strftime(\"%Y-%m-%d\")\n",
    "combined_df.drop(\"startTimeUTC\", axis=1, inplace=True)\n",
    "# combined_df = combined_df[combined_df['game_date'] == formatted_date]\n",
    "combined_df.sort_values(by=\"game_id\")\n",
    "# print(\"combined_df done\")\n",
    "combined_df.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goalies_url = \"https://api-web.nhle.com/v1/goalie-stats-leaders/20242025/2?categories\"\n",
    "\n",
    "# Make the API request\n",
    "response = requests.get(goalies_url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    # The response content can be accessed using response.text\n",
    "    response_text = response.text\n",
    "# pprint(response_text)\n",
    "else:\n",
    "    print(f\"Request failed with status code {response.status_code}\")\n",
    "\n",
    "json_data = json.loads(response_text)\n",
    "json_data.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pctg = json_data[\"savePctg\"]\n",
    "save_pctg_df = pd.DataFrame(save_pctg)\n",
    "save_pctg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaa = json_data[\"goalsAgainstAverage\"]\n",
    "gaa_df = pd.DataFrame(gaa)\n",
    "gaa_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# today's standings\n",
    "\n",
    "api_url = \"https://api-web.nhle.com/v1/standings/2025-03-10\"\n",
    "response = requests.get(api_url)\n",
    "content = json.loads(response.content)\n",
    "\n",
    "\n",
    "# Check if the request was successful (status code 200)\n",
    "if response.status_code == 200:\n",
    "    # The response content can be accessed using response.text\n",
    "    response_text = response.text\n",
    "    # pprint(response_text)\n",
    "else:\n",
    "    print(f\"Request failed with status code {response.status_code}\")\n",
    "\n",
    "json_data = json.loads(response_text)\n",
    "standings = json_data[\"standings\"]\n",
    "standings_df = pd.DataFrame(standings)\n",
    "\n",
    "# Extract team names\n",
    "standings_df[\"team_name\"] = standings_df[\"teamName\"].apply(lambda x: x[\"default\"])\n",
    "standings_df[\"tri_code\"] = standings_df[\"teamAbbrev\"].apply(lambda x: x[\"default\"])\n",
    "standings_df[\"season_id\"] = standings_df[\"seasonId\"]\n",
    "standings_df[\"num_teams\"] = 32\n",
    "standings_df = standings_df[\n",
    "    [\n",
    "        \"team_name\",\n",
    "        \"tri_code\",\n",
    "        \"gamesPlayed\",\n",
    "        \"points\",\n",
    "        \"winPctg\",\n",
    "        \"pointPctg\",\n",
    "        \"regulationPlusOtWins\",\n",
    "        \"goalDifferential\",\n",
    "        \"goalFor\",\n",
    "        \"goalAgainst\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "points_per_game = standings_df[\"points\"] / standings_df[\"gamesPlayed\"]\n",
    "standings_df[\"gf_g\"] = standings_df[\"goalFor\"] / standings_df[\"gamesPlayed\"]\n",
    "standings_df[\"ga_g\"] = standings_df[\"goalAgainst\"] / standings_df[\"gamesPlayed\"]\n",
    "games_remaining = 82 - standings_df[\"gamesPlayed\"]\n",
    "projected_final_points = standings_df[\"points\"] + (games_remaining * points_per_game)\n",
    "standings_df[\"projected_points\"] = round(projected_final_points)\n",
    "current_standings = standings_df\n",
    "current_standings.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://api-web.nhle.com/v1/gamecenter/2023021307/play-by-play\n",
    "# Initialize starting and ending game IDs\n",
    "# start_game_id = 2024020001\n",
    "# end_game_id = 2024021312\n",
    "all_game_ids = combined_df[\"game_id\"].tolist()\n",
    "all_game_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "\n",
    "pxp_url = \"https://api-web.nhle.com/v1/gamecenter/\"\n",
    "pxp_suffix = \"/play-by-play\"\n",
    "\n",
    "game_plays = pd.DataFrame()\n",
    "\n",
    "# Extract all unique game IDs from the DataFrame\n",
    "all_game_ids = combined_df[\"game_id\"].to_list()\n",
    "\n",
    "\n",
    "# Function to process a single game\n",
    "def process_game(game_id):\n",
    "    url = f\"{pxp_url}{game_id}{pxp_suffix}\"\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        json_data = response.json()\n",
    "\n",
    "        if \"plays\" in json_data:\n",
    "            game_plays_detail = pd.json_normalize(json_data[\"plays\"])\n",
    "            game_plays_detail[\"game_id\"] = game_id\n",
    "            game_plays_detail = game_plays_detail[\n",
    "                [\"game_id\"]\n",
    "                + [col for col in game_plays_detail.columns if col != \"game_id\"]\n",
    "            ]\n",
    "            # game_plays_detail = game_plays_detail[\n",
    "            #     game_plays_detail[\"typeCode\"].isin([505, 506, 507, 508])\n",
    "            # ]\n",
    "            return game_plays_detail\n",
    "    else:\n",
    "        print(\n",
    "            f\"Request failed with status code {response.status_code} for game_id {game_id}\"\n",
    "        )\n",
    "\n",
    "    return pd.DataFrame()\n",
    "\n",
    "\n",
    "# Use ThreadPoolExecutor to fetch data in parallel\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:\n",
    "    # Submit requests for all game_ids\n",
    "    future_to_game = {\n",
    "        executor.submit(process_game, game_id): game_id for game_id in all_game_ids\n",
    "    }\n",
    "    for future in concurrent.futures.as_completed(future_to_game):\n",
    "        result = future.result()\n",
    "        if not result.empty:\n",
    "            game_plays = pd.concat([game_plays, result], ignore_index=True)\n",
    "\n",
    "game_plays.dropna(how=\"all\", inplace=True)\n",
    "game_plays.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_plays = game_plays.rename(\n",
    "    columns={\n",
    "        \"periodDescriptor.number\": \"period_number\",\n",
    "        \"periodDescriptor.periodType\": \"period_type\",\n",
    "        \"periodDescriptor.maxRegulationPeriods\": \"max_regulation_periods\",\n",
    "        \"details.eventOwnerTeamId\": \"event_team_id\",\n",
    "        \" details.losingPlayerId \": \"losing_player_id\",\n",
    "        \"details.winningPlayerId\": \"winning_player_id\",\n",
    "        \"details.xCoord\": \"xCoord\",\n",
    "        \"details.yCoord\": \"yCoord\",\n",
    "        \"details.zoneCode\": \"zone_code\",\n",
    "        \"details.reason\": \"reason\",\n",
    "        \"details.hittingPlayerId\": \"hitter\",\n",
    "        \"details.hitteePlayerId\": \"hittee\",\n",
    "        \"details.playerId\": \"player_id\",\n",
    "        \"details.shotType\": \"shot_type\",\n",
    "        \"details.shootingPlayerId\": \"shooting_player\",\n",
    "        \"details.goalieInNetId\": \"goalie\",\n",
    "        \"details.awaySOG\": \"away_sog\",\n",
    "        \"details.homeSOG\": \"home_sog\",\n",
    "        \"details.blockingPlayerId\": \"blocker\",\n",
    "        \"details.scoringPlayerId\": \"scoring_player\",\n",
    "        \"details.scoringPlayerTotal\": \"scoring_player_total\",\n",
    "        \"details.assist1PlayerId\": \"assist_1\",\n",
    "        \"details.assist1PlayerTotal\": \"assist1_total\",\n",
    "        \"details.assist2PlayerId\": \"assist_2\",\n",
    "        \"details.assist2PlayerTotal\": \"assist2_total\",\n",
    "        \"details.awayScore\": \"away_score\",\n",
    "        \"details.homeScore\": \"home_score\",\n",
    "        \"details.secondaryReason\": \"secondary_reason\",\n",
    "        \"details.typeCode\": \"type_code\",\n",
    "        \"details.descKey\": \"desc_key\",\n",
    "        \"details.duration\": \"duration\",\n",
    "        \"details.committedByPlayerId\": \"committed_by\",\n",
    "        \"details.drawnByPlayerId\": \"drawn_by\",\n",
    "        \"details.servedByPlayerId\": \"served_by\",\n",
    "    }\n",
    ")\n",
    "\n",
    "game_plays.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to make the shot data more readable\n",
    "situation_dictionary = {\n",
    "    \"1551\": \"5 on 5\",\n",
    "    \"1451\": \"5 on 4\",\n",
    "    \"1541\": \"5 on 4\",\n",
    "    \"0651\": \"6 on 5\",\n",
    "    \"1560\": \"6 on 5\",\n",
    "    \"1441\": \"4 on 4\",\n",
    "    \"1331\": \"3 on 3\",\n",
    "    \"1460\": \"6 on 4\",\n",
    "    \"1351\": \"5 on 3\",\n",
    "    \"0641\": \"6 on 4\",\n",
    "    \"1341\": \"4 on 3\",\n",
    "    \"0101\": \"1 on 1\",\n",
    "    \"1531\": \"5 on 3\",\n",
    "    \"1010\": \"1 on 1\",\n",
    "    \"1431\": \"4 on 3\",\n",
    "    \"0440\": \"4 on 4\",\n",
    "    \"0541\": \"5 on 4\",\n",
    "    \"1550\": \"5 on 5\",\n",
    "    \"1450\": \"5 on 4\",\n",
    "    \"0551\": \"5 on 5\",\n",
    "    \"0431\": \"4 on 3\",\n",
    "    \"1340\": \"4 on 3\",\n",
    "    \"0451\": \"5 on 4\",\n",
    "    \"0531\": \"5 on 4\",\n",
    "    \"0631\": \"6 on 3\",\n",
    "    \"1360\": \"6 on 3\",\n",
    "    \"1350\": \"5 on 4\",\n",
    "    \"1440\": \"4 on 4\",\n",
    "}\n",
    "\n",
    "game_plays[\"situation\"] = game_plays[\"situationCode\"].map(situation_dictionary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# G - goalie on ice for away team\n",
    "\n",
    "# I - on ice skaters for away team\n",
    "\n",
    "# i - on ice skaters for home team\n",
    "\n",
    "# g - goalie on ice for home team\n",
    "game_plays[\"goalie_situation\"] = np.where(\n",
    "    (game_plays[\"situationCode\"].str.startswith(\"0\"))\n",
    "    | (game_plays[\"situationCode\"].str[3] == \"0\"),\n",
    "    \"pulled\",\n",
    "    \"in net\",\n",
    ")\n",
    "\n",
    "game_plays.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_plays = game_plays.rename(columns={\"event_team_id\": \"team_id\"})\n",
    "game_plays.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'timeRemaining' (MM:SS) format into total seconds\n",
    "game_plays[\"game_in_seconds\"] = game_plays[\"timeInPeriod\"].apply(\n",
    "    lambda x: int(x.split(\":\")[0]) * 60 + int(x.split(\":\")[1])\n",
    "    if isinstance(x, str)\n",
    "    else x\n",
    ")\n",
    "game_plays.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Define shot attempts and transition events\n",
    "shot_events = {\n",
    "    \"shot-on-goal\",\n",
    "    \"missed-shot\",\n",
    "    \"goal\",\n",
    "    \"blocked-shot\",\n",
    "    \"failed-shot-attempt\",\n",
    "}\n",
    "transition_events = {\"giveaway\", \"takeaway\", \"hit\"}\n",
    "valid_prev_events = shot_events | transition_events  # Combine into one valid set\n",
    "\n",
    "# Filter only rows where events are relevant (either shots or transition events)\n",
    "valid_plays = game_plays[game_plays[\"typeDescKey\"].isin(valid_prev_events)]\n",
    "\n",
    "# Sort by game time within each game\n",
    "valid_plays = valid_plays.sort_values([\"game_id\", \"game_in_seconds\"])\n",
    "\n",
    "# Create columns for the previous eventâ€™s time, zone, and type for each team\n",
    "valid_plays[\"prev_event_time\"] = valid_plays.groupby([\"game_id\", \"team_id\"])[\n",
    "    \"game_in_seconds\"\n",
    "].shift(1)\n",
    "valid_plays[\"prev_zone\"] = valid_plays.groupby([\"game_id\", \"team_id\"])[\n",
    "    \"zone_code\"\n",
    "].shift(1)\n",
    "valid_plays[\"prev_event_type\"] = valid_plays.groupby([\"game_id\", \"team_id\"])[\n",
    "    \"typeDescKey\"\n",
    "].shift(1)\n",
    "\n",
    "# Calculate time difference\n",
    "valid_plays[\"time_diff\"] = (\n",
    "    valid_plays[\"game_in_seconds\"] - valid_plays[\"prev_event_time\"]\n",
    ")\n",
    "\n",
    "# Filter for rush shots\n",
    "rush_df = valid_plays[\n",
    "    (valid_plays[\"typeDescKey\"].isin(shot_events))  # Must be a shot\n",
    "    & (valid_plays[\"time_diff\"] <= 4)  # Must occur within 4 seconds\n",
    "    & (valid_plays[\"prev_zone\"].isin({\"D\", \"N\"}))  # Previous event must be in DZ or NZ\n",
    "]\n",
    "\n",
    "rush_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_shots_made = game_plays.copy()\n",
    "all_shots_made[\"typeDescKey\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_shots_made = all_shots_made[all_shots_made[\"typeCode\"].isin([505, 506, 507, 508])]\n",
    "all_shots_made.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_shots_made[\"goalie\"] = all_shots_made[\"goalie\"].fillna(0)\n",
    "# nan_rows = all_shots_made[all_shots_made['goalie'].isna()]\n",
    "# print(nan_rows)\n",
    "all_shots_made[\"goalie\"] = all_shots_made[\"goalie\"].astype(\"int64\")\n",
    "all_shots_made.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Danger zone\n",
    "\n",
    "\n",
    "# Define conditions based on the corrected MD and HD coordinates\n",
    "\n",
    "# High Danger Zone (HD) - Right side of the rink\n",
    "hd_condition_right = (\n",
    "    (all_shots_made[\"xCoord\"] >= 66.5)\n",
    "    & (all_shots_made[\"xCoord\"] <= 89)\n",
    "    & (all_shots_made[\"yCoord\"] >= -7)\n",
    "    & (all_shots_made[\"yCoord\"] <= 7)\n",
    ")\n",
    "\n",
    "# High Danger Zone (HD) - Left side of the rink (mirrored)\n",
    "hd_condition_left = (\n",
    "    (all_shots_made[\"xCoord\"] >= -89)\n",
    "    & (all_shots_made[\"xCoord\"] <= -66.5)\n",
    "    & (all_shots_made[\"yCoord\"] >= -7)\n",
    "    & (all_shots_made[\"yCoord\"] <= 7)\n",
    ")\n",
    "\n",
    "# Medium Danger Zone (MD) - Right side\n",
    "md_condition_right = (\n",
    "    (\n",
    "        (all_shots_made[\"xCoord\"] >= 69)\n",
    "        & (all_shots_made[\"xCoord\"] <= 89)\n",
    "        & (all_shots_made[\"yCoord\"] >= -22)\n",
    "        & (all_shots_made[\"yCoord\"] <= -7)\n",
    "    )\n",
    "    | (\n",
    "        (all_shots_made[\"xCoord\"] >= 54)\n",
    "        & (all_shots_made[\"xCoord\"] <= 69)\n",
    "        & (all_shots_made[\"yCoord\"] >= -22)\n",
    "        & (all_shots_made[\"yCoord\"] <= 22)\n",
    "    )\n",
    "    | (\n",
    "        (all_shots_made[\"xCoord\"] >= 40)\n",
    "        & (all_shots_made[\"xCoord\"] <= 54)\n",
    "        & (all_shots_made[\"yCoord\"] >= -7)\n",
    "        & (all_shots_made[\"yCoord\"] <= 7)\n",
    "    )\n",
    ")\n",
    "\n",
    "# Medium Danger Zone (MD) - Left side (mirrored)\n",
    "md_condition_left = (\n",
    "    (\n",
    "        (all_shots_made[\"xCoord\"] >= -89)\n",
    "        & (all_shots_made[\"xCoord\"] <= -69)\n",
    "        & (all_shots_made[\"yCoord\"] >= -22)\n",
    "        & (all_shots_made[\"yCoord\"] <= -7)\n",
    "    )\n",
    "    | (\n",
    "        (all_shots_made[\"xCoord\"] >= -69)\n",
    "        & (all_shots_made[\"xCoord\"] <= -54)\n",
    "        & (all_shots_made[\"yCoord\"] >= -22)\n",
    "        & (all_shots_made[\"yCoord\"] <= 22)\n",
    "    )\n",
    "    | (\n",
    "        (all_shots_made[\"xCoord\"] >= -54)\n",
    "        & (all_shots_made[\"xCoord\"] <= -40)\n",
    "        & (all_shots_made[\"yCoord\"] >= -7)\n",
    "        & (all_shots_made[\"yCoord\"] <= 7)\n",
    "    )\n",
    ")\n",
    "\n",
    "# Low Danger Zone (LD) - Every other coordinate\n",
    "ld_condition = ~(\n",
    "    hd_condition_right | hd_condition_left | md_condition_right | md_condition_left\n",
    ")\n",
    "\n",
    "# Apply conditions to classify shots\n",
    "conditions = [\n",
    "    hd_condition_right | hd_condition_left,\n",
    "    md_condition_right | md_condition_left,\n",
    "    ld_condition,\n",
    "]\n",
    "values = [\"HD\", \"MD\", \"LD\"]\n",
    "\n",
    "all_shots_made[\"shot_danger\"] = np.select(conditions, values, default=\"LD\")\n",
    "\n",
    "# Create new columns for HD, MD, and LD shots\n",
    "all_shots_made[\"hd_shot\"] = (all_shots_made[\"shot_danger\"] == \"HD\").astype(int)\n",
    "all_shots_made[\"md_shot\"] = (all_shots_made[\"shot_danger\"] == \"MD\").astype(int)\n",
    "all_shots_made[\"ld_shot\"] = (all_shots_made[\"shot_danger\"] == \"LD\").astype(int)\n",
    "all_shots_made.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_shots_made[\"game_time\"] = (\n",
    "    all_shots_made[\"period_number\"] - 1\n",
    ") * 1200 + all_shots_made[\"game_in_seconds\"]\n",
    "\n",
    "# Sort by game_id and game_time\n",
    "# all_shots_made = all_shots_made.sort_values(by=['game_id', 'game_time'])\n",
    "\n",
    "# Calculate time difference from the last shot in the same game\n",
    "all_shots_made[\"time_since_last_shot\"] = all_shots_made.groupby(\"game_id\")[\n",
    "    \"game_time\"\n",
    "].diff()\n",
    "\n",
    "# Define a rebound as a shot that follows another shot within 3 seconds\n",
    "all_shots_made[\"is_rebound\"] = (all_shots_made[\"time_since_last_shot\"] <= 3).astype(int)\n",
    "\n",
    "all_shots_made.head()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
